{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic ideas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## the big picture: how to use tf to learn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "用tf进行机器学习, 需要的是: \n",
    "\n",
    "1. 定义输入数据的*placeholder*(\"占位符\"), 比如输入的数据x和标签y_truth\n",
    "2. 定义要优化的模型参数*Variable*\n",
    "3. 用上面输入数据(*的placeholder*)和模型参数(Variable)描述模型输出的预测结果y_pred: y_pred是由placeholders和variables经过一系列操作(op)得到的\n",
    "4. 用y_pred, 以及输入数据的y_truth, 描述一个损失函数cost: y_pred越接近y_truth, 则cost越小, 常用的cost有: MSE, cross_entropy\n",
    "5. 选择一个优化器optimizer, 这里的optimizer一般是某种梯度下降算法\n",
    "6. 在每个iteration中: 给那些placeholder喂入训练的batch数据(不是占位符而是实际数值), 用优化器进行一次迭代(优化器进行一次梯度下降，更新模型参数从而减小cost)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## batch, iteration, epoch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* batch不用解释了吧. batch的大小程序里一般叫做`batch_size`\n",
    " \n",
    "* 一个iteration就是在跑一个batch的过程, 可以得到这个batch上的loss和accuracy等. 不指定`nb_epochs`的话也可以设置`max_iter`, 设置iteration的最大次数(比较少用). \n",
    "\n",
    "* 一个epoch是跑K个batch(iteration)直到把所有training set数据过一遍的过程. 这里这个 K=trainingset_size/batch_size. 程序里一般把这个K起名叫做`total_batch`, `nb_epochs` 指定程序在数据上跑的遍数. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## why computational graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "为什么要使用placeholder和Variable这种方式描述计算图(computational graph)? \n",
    "\n",
    "用计算图虽然不能像普通py程序那样直观(每一步计算都立刻执行并且得到结果), 但是用计算图的方式有以下好处:\n",
    "\n",
    "1. 最重要的一点是, 用计算图的方式以后, tf可以**自动求导**!! \n",
    "2. 可以在后期进行优化, 去掉不必要操作. 比如下面的代码: \n",
    "\n",
    "        a = x / y\n",
    "        # ...\n",
    "        b = y / z\n",
    "        # ...\n",
    "        final_res = a * b\n",
    "\n",
    "    上面程序中, a和b这两个中间变量的计算是可以化简的. 如果用计算图实现的话, 程序就可以在后期将最后结果简化为 `x/z`, 从而提高运行效率. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## placeholder, variable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## activation function: relu, softmax, sigmoid..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## loss: cross entropy, KL divergence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## optimizer: how to choose"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "关于optimizer的选择, 根据[这个帖子](https://www.quora.com/How-do-I-choose-an-optimizer-for-my-tensorflow-model), 对于浅层网络, 用sgd/Nesterov, 深层网络用adam/rmsprop."
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:thesis_nb]",
   "language": "python",
   "name": "conda-env-thesis_nb-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
